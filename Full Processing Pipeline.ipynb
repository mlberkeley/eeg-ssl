{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing.py\n",
    "Ana Cismaru and Alfredo Andere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mne\n",
    "from mne import preprocessing\n",
    "import pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook uses the Sleep Cassette Study (153 recordings in .edf format) and Data from Sleep EDF Expanded Dataset\n",
    "Link: https://physionet.org/content/sleep-edfx/1.0.0/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Upload Data </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input: String that contains folder name of folder with PSG.edf files\n",
    "\n",
    "\n",
    "Output: list of MNE Raw Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"sleep-cassette\"\n",
    "\n",
    "def upload_raw(data_folder):\n",
    "    mne_raw = []\n",
    "\n",
    "    for path in os.listdir(data_folder):\n",
    "        if path.endswith(\"-PSG.edf\"):\n",
    "            full_path = os.path.join(data_folder, path)\n",
    "            raw = mne.io.read_raw_edf(full_path, preload=True)\n",
    "            mne_raw.append(raw)\n",
    "    return mne_raw\n",
    "\n",
    "mne_raw = upload_raw(data_folder)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Plot upload </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mne_raw[2].plot_psd()\n",
    "mne_raw[2].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Remove Non EEG Channels </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input: list of MNE Raw Objects\n",
    "\n",
    "Output: list of MNE Raw Objects with only EEG channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For sleep edf, manual extraction because mne.pick_types isn't working\n",
    "\n",
    "def remove_sleepEDF(mne_raw):\n",
    "    mne_eeg = []\n",
    "    for point in mne_raw:\n",
    "        mne_eeg.append(point.pick_channels([\"EEG Fpz-Cz\", \"EEG Pz-Oz\"]))\n",
    "    return mne_eeg\n",
    "\n",
    "mne_eeg = remove_sleepEDF(mne_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In general\n",
    "def remove(mne_raw):\n",
    "    mne_eeg_gen = []\n",
    "    for point in mne_raw:\n",
    "        mne_eeg_gen.append(point.pick_types(eeg = True))\n",
    "    return mne_eeg_gen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Filter 30 HZ 4th-order FIR lowpass filter </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input: list of MNE Raw Objects with only EEG chaneels\n",
    "\n",
    "Output: list of filtered MNE Raw Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter(mne_eeg):\n",
    "    mne_filtered = []\n",
    "    for point in mne_eeg:\n",
    "        point2 = point.filter(l_freq=None,\n",
    "                h_freq=30,\n",
    "                picks = [\"EEG Fpz-Cz\", \"EEG Pz-Oz\"],\n",
    "                filter_length = \"auto\",\n",
    "                method = \"fir\"\n",
    "                )\n",
    "        mne_filtered.append(point2)\n",
    "    return mne_filtered\n",
    "mne_filtered = filter(mne_eeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Divide into 30s samples\n",
    "Input: E’ - a mne data structure of n number of recordings and t seconds each. <p>\n",
    "Output: E - dataset of epochs e of 30 seconds but temporally ordered. \n",
    "        #epochs = |E’| = (n * t) / 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_events(raw, epoch_length):\n",
    "    \"\"\"Create events to split raw into epochs.\"\"\"\n",
    "    file_length = raw.n_times\n",
    "    first_samp = raw.first_samp\n",
    "    sfreq = raw.info['sfreq']\n",
    "    n_samp_in_epoch = int(epoch_length * sfreq)\n",
    "\n",
    "    n_epochs = int(file_length // n_samp_in_epoch)\n",
    "\n",
    "    events = []\n",
    "    for i_epoch in range(n_epochs):\n",
    "        events.append([first_samp + i_epoch * n_samp_in_epoch, int(0), int(0)])\n",
    "    events = np.array(events)\n",
    "    return events\n",
    "\n",
    "\n",
    "def divide_epochs(raw, e_len):\n",
    "    \"\"\" Divides the mne dataset into many samples of length e_len seconds.\n",
    "    \n",
    "    Args:\n",
    "        E: mne data structure\n",
    "        e_len: (int seconds) length of each sample\n",
    "        \n",
    "    Returns:\n",
    "        epochs: mne data structure of (experiment length * users) / e_len \"\"\"\n",
    "    if raw.times[-1] >= e_len:\n",
    "        events = _create_events(raw, e_len)\n",
    "    print(events)\n",
    "    epochs = mne.Epochs(raw, events=events, tmax=e_len, preload=True) \n",
    "    return epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Downsample to 128 Hz and 3 channels \t[for MASS = 256 Hz]\n",
    "Input: E’  - a mne data structure sampled at a rate r’ > 128 Hz <p>\n",
    "Output: E’ - a mne data structure sampled at a rate r of 128 Hz. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(epochs, chs, Hz=128):\n",
    "    \"\"\" Downsample the EEG epoch to Hz=128 Hz and to only \n",
    "        include the channels in ch.\n",
    "    \n",
    "        Args: \n",
    "            epochs: mne data structure sampled at a rate r’ > 128 Hz\n",
    "            chs: list of the channels to keep\n",
    "            Hz: Hz to downsample to (default 128 Hz)\n",
    "        Returns\n",
    "            E: a mne data structure sampled at a rate r of 128 Hz.\n",
    "    \"\"\"\n",
    "    # ch_id = [epochs.ch_names.index(ch) for ch in chs]\n",
    "    E = epochs.pick_types(eeg=True, selection=chs)\n",
    "    E = E.resample(Hz, npad='auto')\n",
    "    return E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalization by sample \n",
    "Input: E’ - dataset (ds) of mne epoch objects e\n",
    "Output: E  ds of mne epoch objects normalized s.t <p>\n",
    "        mean(e)= 0, var(e) = 1 eE <p>\n",
    "Return E - Dataset of normalized e "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _normalize(epoch):\n",
    "    return (epoch - epoch.mean()) / epoch.var()\n",
    "\n",
    "def normalization(epochs):\n",
    "    \"\"\" Normalizes each epoch e s.t mean(e)=mean and var(e)=variance\n",
    "    \n",
    "        Args:\n",
    "            epochs - Numpy structure of epochs\n",
    "        \n",
    "        Returns:\n",
    "            epochs_n - mne data structure of normalized epochs (mean=0, var=1)\n",
    "    \"\"\"\n",
    "    for i in range(epochs.shape[0]):\n",
    "        epochs[i,:,:] = _normalize(epochs[i,:,:])\n",
    "    \n",
    "    return epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Return E - Dataset of labeled e "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __main__1():\n",
    "    SAMPLE_TIME = 30\n",
    "    CHANNELS = ['EEG Fpz-Cz', 'EEG Pz-Oz']\n",
    "    \n",
    "    raw = actual_data() # switch to \n",
    "    raw.plot()\n",
    "    print(f\"raw info: {raw.info}\")\n",
    "    \n",
    "    epochs = divide_epochs(raw, SAMPLE_TIME)\n",
    "    epochs.plot()\n",
    "\n",
    "    epochs = downsample(epochs, CHANNELS)\n",
    "    epochs.plot()\n",
    "    print(f\"epochs info: {epochs.info}\")\n",
    "    \n",
    "    epochs = epochs.get_data() # turns into NumPy Array\n",
    "    \n",
    "    print(f\"mean: {epochs.mean()}\")\n",
    "    print(f\"variance: {epochs.var()}\")\n",
    "    f_epochs = normalization(epochs)\n",
    "    \n",
    "    print()\n",
    "    print(\"-------Info on Data ---------\")\n",
    "    print(f\"epoch shape: {epochs.shape} = (epochs, channels, samples/p/channel (30sec * Hz))\")\n",
    "    print(f\"sampling_rate: {epochs.shape[2] / 30}\")\n",
    "    print(f\"mean: {epochs.mean()}\")\n",
    "    print(f\"variance: {epochs.var()}\")\n",
    "    \n",
    "    return f_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = __main__1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temporal Shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temporal_shuffling(epochs, T_pos, T_neg):\n",
    "    \"\"\" Builds a self-supervised (temporal shuffling) dataset of epochs \n",
    "    \n",
    "    Args:\n",
    "        E - Numpy datset of time-series arrays\n",
    "        T_pos - positive context to sample from\n",
    "        T_neg - negative context to sample from\n",
    "        \n",
    "    Output:\n",
    "        TS_dataset - Temporal Shuffling Dataset of dimensions (L, 4, s, c)\n",
    "            L - # of samples = # of user * # of epochs per user * 6\n",
    "            3 - sample1 + sample2 + sample3\n",
    "            s - # of eeg channels in each sample\n",
    "            c - Samples per channel = 30s * 128Hz\n",
    "        TS_labels - Temporal Shuffling labels of dimensions (L, 1)\n",
    "            for each y = {1: if sample1 < sample2 < sample3 and -1: otherwise}\n",
    "            \"\"\"\n",
    "    np.random.seed(420) # If we live in a deterministic world, should we even seed our pseudorandoms?\n",
    "    random.seed(69)\n",
    "    \n",
    "    total_samples = epochs.shape[0] * 6\n",
    "    TS_dataset = np.empty((total_samples, 3, epochs.shape[1], 3867), int)\n",
    "    TS_labels = np.empty((total_samples, 1))\n",
    "    counter = 0\n",
    "    ## need to add a variable here once our data is ready\n",
    "    for user in range(1):\n",
    "        for idx, sample1 in enumerate(epochs):\n",
    "            for _ in range(3):\n",
    "                sample2_index = np.random.randint(max(idx-T_pos, 0), min(idx+T_pos, epochs.shape[0]-1))\n",
    "                while sample2_index == idx: # should not be the same\n",
    "                    sample2_index = np.random.randint(max(idx-T_pos, 0), min(idx+T_pos, epochs.shape[0]-1))                    \n",
    "                sample2 = epochs[sample2_index]\n",
    "                \n",
    "                if idx-T_neg <= 0: # T_neg if (corners)\n",
    "                    sample3_index = np.random.randint(idx+T_neg, epochs.shape[0])\n",
    "                elif idx+T_neg >= epochs.shape[0]: # take care of low == high\n",
    "                    sample3_index = np.random.randint(0, idx-T_neg)\n",
    "                else:\n",
    "                    sample3_index_1 = np.random.randint(idx+T_neg, epochs.shape[0])\n",
    "                    sample3_index_2 = np.random.randint(0, idx-T_neg)\n",
    "                    sample3_index = list([sample3_index_1, sample3_index_2])[int(random.uniform(0,1))]\n",
    "                sample3 = epochs[sample3_index]\n",
    "                \n",
    "                if idx < sample2_index and sample2_index < sample3_index:\n",
    "                    y = 1\n",
    "                else:\n",
    "                    y = -1\n",
    "\n",
    "                TS_sample = np.array([sample1, sample2, sample3])\n",
    "                TS_dataset[counter] = TS_sample\n",
    "                TS_labels[counter] = y\n",
    "                counter += 1\n",
    "                \n",
    "            for _ in range(3): # T_neg loop\n",
    "                sample2_index = np.random.randint(max(idx-T_pos, 0), min(idx+T_pos, epochs.shape[0]-1))\n",
    "                while sample2_index == idx: # should not be the same\n",
    "                    sample2_index = np.random.randint(max(idx-T_pos, 0), min(idx+T_pos, epochs.shape[0]-1))                    \n",
    "                sample2 = epochs[sample2_index]\n",
    "                \n",
    "                sample3_index = np.random.randint(max(idx-T_pos, 0), min(idx+T_pos, epochs.shape[0]-1))\n",
    "                while sample2_index == sample3_index or sample3_index == idx: # should not be the same\n",
    "                    sample3_index = np.random.randint(max(idx-T_pos, 0), min(idx+T_pos, epochs.shape[0]-1))\n",
    "                sample3 = epochs[sample3_index]\n",
    "\n",
    "                if idx < sample2_index and sample2_index < sample3_index:\n",
    "                    y = 1\n",
    "                else:\n",
    "                    y = -1\n",
    "                    \n",
    "                TS_sample = np.array([sample1, sample2, sample3])\n",
    "                TS_dataset[counter] = TS_sample\n",
    "                TS_labels[counter] = y\n",
    "                counter += 1\n",
    "    np.save('TS_dataset', TS_dataset)\n",
    "    np.save('TS_labels', TS_labels)\n",
    "    return TS_dataset, TS_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __mainTS__():\n",
    "    TS_dataset, TS_labels = temporal_shuffling(data1, 3, 3)\n",
    "    return TS_dataset, TS_labels  # The actual one will not return anything and will save the dataset to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TS_dataset, TS_labels = __mainTS__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relative Positioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relative_positioning(epochs, T_pos, T_neg):\n",
    "    \"\"\" Builds a self-supervised (relative positioning) dataset of epochs \n",
    "    \n",
    "    Args:\n",
    "        E - Numpy datset of time-series arrays\n",
    "        T_pos - positive context to sample from\n",
    "        T_neg - negative context to sample from\n",
    "        \n",
    "    Output:\n",
    "        TS_dataset - Temporal Shuffling Dataset of dimensions (L, 3, s, c)\n",
    "            L - # of samples = # of user * # of epochs per user * 6\n",
    "            2 - sample1 + sample2\n",
    "            s - # of eeg channels in each sample\n",
    "            c - Samples per channel = 30s * 128Hz\n",
    "        TS_labels - Temporal Shuffling labels of dimensions (1, L)\n",
    "            for each y = {1: if |sample1-sample2| < T_pos and -1: if |sample1-sample2| > T_neg}\n",
    "            \"\"\"\n",
    "    np.random.seed(420) # If we live in a deterministic world, should we even seed our pseudorandoms?\n",
    "    random.seed(69)\n",
    "    \n",
    "    total_samples = epochs.shape[0] * 6\n",
    "    RP_dataset = np.empty((total_samples, 2, epochs.shape[1], 3867), int)\n",
    "    RP_labels = np.empty((total_samples, 1))\n",
    "    counter = 0\n",
    "    ## need to add a variable here once our data is ready\n",
    "    for user in range(1):\n",
    "        for idx, sample1 in enumerate(epochs):\n",
    "            for _ in range(3): # Loop for T_pos\n",
    "                sample2_index = np.random.randint(max(idx-T_pos, 0), min(idx+T_pos, epochs.shape[0]-1))\n",
    "                while sample2_index == idx: # should not be the same\n",
    "                    sample2_index = np.random.randint(max(idx-T_pos, 0), min(idx+T_pos, epochs.shape[0]-1))                    \n",
    "                sample2 = epochs[sample2_index]\n",
    "                \n",
    "                y = 1\n",
    "\n",
    "                RP_sample = np.array([sample1, sample2])\n",
    "                RP_dataset[counter] = RP_sample\n",
    "                RP_labels[counter] = y\n",
    "                counter += 1\n",
    "                \n",
    "            for _ in range(3): # Loop for T_neg\n",
    "                if idx-T_neg <= 0: # T_neg if (corners)\n",
    "                    sample2_index = np.random.randint(idx+T_neg, epochs.shape[0])\n",
    "                elif idx+T_neg >= epochs.shape[0]: # take care of low == high\n",
    "                    sample2_index = np.random.randint(0, idx-T_neg)\n",
    "                else:\n",
    "                    sample2_index_1 = np.random.randint(idx+T_neg, epochs.shape[0])\n",
    "                    sample2_index_2 = np.random.randint(0, idx-T_neg)\n",
    "                    sample2_index = list([sample2_index_1, sample2_index_2])[int(random.uniform(0,1))]\n",
    "                sample2 = epochs[sample2_index]\n",
    "\n",
    "                y = -1\n",
    "                    \n",
    "                RP_sample = np.array([sample1, sample2])\n",
    "                RP_dataset[counter] = RP_sample\n",
    "                RP_labels[counter] = y\n",
    "                counter += 1\n",
    "    np.save('RP_dataset', RP_dataset)\n",
    "    np.save('RP_labels', RP_labels)\n",
    "    return RP_dataset, RP_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __mainRP__():\n",
    "    relative_positioning(data1, 3, 3)\n",
    "    return RP_dataset, RP_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RP_dataset, RP_labels = __mainRP__()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p37",
   "language": "python",
   "name": "p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
